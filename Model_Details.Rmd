---
title: "Wood River Water Collaborative Predictive Streamflow and Curtailment Date Model Details"
author: "Kendra Kaiser, n\ Boise State University, n\ Department of Geosciences"
date: "01/19/2021"
output: 
  pdf_document:
    toc: yes
    toc_depth: 3
  highlight: tango
urlcolor: blue
csl: AmJBot.csl
header-includes:
    \usepackage{float}
params:
    fig_dir_mo: 'figures/April'
---
\newpage
```{r include=FALSE}
library(knitr)
library(tidyverse)
usgs_sites = read.csv('~/Desktop/WRWC/data/usgs_sites.csv')
snotel_sites = read.csv('~/Desktop/WRWC/data/snotel_sites.csv')
```

# 1. Introduction
The Wood River Collaborative is a grassroots effort to tackle water usage challenges among irrigators, municipalities, and protect minimum flows for fish and wildlife habitat. Its many, basin-wide participants include private citizens, representatives of water agencies, non-profit organizations, private interests and the public sector. The outcome of the collaboration is to bring all stakeholders together and develop strategies and tools for best use of water for consumptive use, while conserving water for groundwater and in-stream flows.

The following suite of modeling tools were developed in response to stakeholder interests in improving management of surface and groundwater resources for agriculture and conservation purposes. These tools include automated data retrieval and organization for use in predictive models of irrigation season streamflow volume and timing in the Big Wood River Basin at the Hailey and Stanton Crossing gages, Camas Creek, and Silver Creek at Sportsman's Access (Figure 1). Annual river diversions are also predicted to estimate curtailment dates for three water right priority dates. 

```{r, Map, echo=FALSE, fig.cap="Map of the Big Wood River, Camas Creek and Silver Creek Watersheds and locations of automated data", fig.aling="left", out.width = '90%'}
knitr::include_graphics("figures/WRWC_ModelDomain.png")
```


# 2. Methodology & Model Fits

## Overview 
Individual multivariate linear regression models were developed for each of these locations using USGS streamflow data, Snotel SWE and temperature data, AgriMet temperature data, and diversion data from Water District 37 (Table 1). The Baysian Information Criterion (BIC, 2008) was used to select model parameters for each of the gage locations for total irrigation season streamflow volume and timing, characterized by the center of mass. Center of mass is the mean of the probability distribution of April - September streamflow, or the date of the "mean" streamflow between April and September. Linear regressions were also created to estimate total diversions in the Big Wood above Stanton Crossing and in Silver Creek above Sportsmans' Access. These predicted diversions are subtracted from the USGS gage data to predict "natural" flow at each gage. This "natural" flow is needed to predict curtailment dates. 

```{r, Data_sources, echo=FALSE, fig.aling="left", out.width = '90%'}
knitr::include_graphics("figures/Data_sources.png")
```

Once the linear regression models were developed for total irrigation season volume, diversions, and timing at each location, multivariate distributions were used to stochastically model hydrographs for each location. The residuals (standard error) from each of the regression models and correlations between gauge stations are used to create the multivariate distributions. This ensures that given a set of predictor variables (e.g. SWE, temp) the predicted volumes will be statistically consistent across gage locations (e.g. the models wont predict that Camas Creek will have really low runoff year while the Big Wood has a really high runoff year because they are statistically correlated). Repeated, random selection from these multivariate distributions produces a `sample` of predicted volumes and timing of streamflow. The samples of total volume and streamflow timing are then used to create simulations of the irrigation season hydrograph. Variability in final model outputs is quantified by percentiles of the resulting predictions. 

The methods for predicting curtailments dates currently follow those for streamflow timing, where once the linear regressions are made the covariance between curtailment dates are used to create a multivariate distribution from which potential dates are sampled from.

The suite of linear regression models are unique to each run date, February 1st, March 1st and April 1st. In February and March, the linear regressions for diversions above the Big Wood at Stanton gage did not preform well, so the diversions are sampled from a normal distribution created from the historic data. The curtailment models are currently only in the April model run, this is largely due to the high uncertainty in the results of these models. This uncertainty largely comes from the compounding uncertainty from predictions of total seasonal streamflow volume, temperatures and diversions.

```{r, Model_Workflow, echo=FALSE, fig.aling="left", out.width = '80%'}
knitr::include_graphics("figures/ModelWorkflow_details.png")
```

## Reproducibility

All model scripts have been developed using gitHub as the code repository. This enables tracking of all model changes, sharing of model code with WRWC members and a mechanism for users to post 'issues' to the code repository (`https://github.com/kendrakaiser/WRWC`). When the model is updated a versioning standard will be used to update 


## 2.1 Data Downloading and Organization
Automation of data downloads and processing ensures that all data is formatted properly. Creating a local folder for each model run where all formatted data is saved will be valuable for reproducibility purposes.

### USGS

```{r, Historic_streamflow, echo=FALSE, fig.show='hold', out.width="50%"}
knitr::include_graphics(c("figures/historic_streamflow.png", "figures/historic_streamflow_sc.png"))
```
```{r, usgs-sites, echo=FALSE, fig.show='hold', out.width="80%"}
kable(usgs_sites[c(1,2,3,5),] %>% dplyr::select(station_nm, huc_cd, begin_date, end_date, abv), caption = "USGS Sites")
```

### Snotel

Snotel data from all locations in the Big Wood, Camas Creek and Little Wood drainages are included in the automated data downloading. This data includes snow water equivalent (SWE), cumulative precipitation, max, min and average daily temperatures.

```{r data inputs, , out.width="65%"}
kable(snotel_sites %>% dplyr::select(start, end, site_name, huc8, abv), caption = "Snotel Sites")
```

### Agrimet
A specific function has been developed to download the AgriMet data without timing-out the servers. This has been added to the `code` folder (`grabAgriMetData.R`) to make installation easier. Temperature data from Fairfield and Picabo are included. 

### Snow Cover Extent

Remotely sensed snow cover extent was explored as a means to represent snow derived water availability in conjunction with Snotel data for the predictive streamflow model. Google Earth Engine (GEE) was used to extract snow covered extent (SCE) from Landsat images (16 day return interval, 30m resolution). For the purposes of this exploratory analysis, data from Landsat5 TM from 1983-2013 was used. A GEE script gathers all images over the Wood River Basin (WRB), filters out pixels that are cloud covered, or otherwise problematic, and applies the Normalized Difference Snow Index (NDSI) to the remaining pixels. Although this analysis lead to 408 total images that have greater than 50% coverage (clear pixels), very few of these images cover winter months. Additional modeling will be needed to use any remotely sensed snow cover data.

### Diversion & Curtailment Data
This data was compiled by WRWC by manually entering data from the irrigation district black books
and should be updated annually for future model revisions. Currently the following diversions are included:

BWB: Tom P2, Lewis 1, Ketchum 2, McCoy 3, Peters 17C1, Hiawatha 22, Osborn24, and Cove 33 (above Hailey), WRVID 45, Bannon 49, Glendale 50, Baseline 55, Brown 57F1, Brown 57F2, Black 61, Graf 62, Uhrig 63, Flood 64
SC: Teeter Canyon P5,	Stalker Creek P7,	Gillihan Bashaw,	Gillihan Picabo Live,	Gillihan Woods,	Stanfield 13,	Albrethson 17,	Kilpatrick 18,	Iden 19 Fish and Game,	Iden 19 Picabo Livestock

Smaller diversions were not included in this model version as they were considered to be minor given time constraints.

```{r, Historic_diversions, echo=FALSE, fig.show='hold', out.width="50%"}
knitr::include_graphics(c(file.path(params$fig_dir_mo, "Div.bw.png"), file.path(params$fig_dir_mo, "Div.sc.png")))
```

## 2.2 Temperature Model

A linear mixed effects model was developed to predict mean April - June temperatures in each sub basin. April - June temperatures are predictors in the center of mass regressions, so a bootstrapped sample of predicted temperatures are used.

```{python, echo=TRUE, eval=FALSE, python.reticulate=FALSE}
#subset sites to those for each sub basin
tdata.bwb<- tdata[tdata$site %in% c("galena","galena summit", "lost-wood divide"),]
trend.reml<-lme(fixed=Apr.Jun.tempF ~ year, random=~1+year|site, correlation = corAR1(), data=tdata.bwb, method="REML",na.action=na.omit)
# predict this years temperature
pred<-predict(trend.reml,new.data,0:1)$predict.fixed[1]
fits<-fitted(trend.reml,0:1)[(1:nyrs),1]
# Bootstrap to estimate variance on new prediction, based on fixed-effects covariance matrix
mu<-trend.reml$coef$fixed
sig<-trend.reml$var
rand.coefs<-mvrnorm(nboots,mu,sig)
var.est<-var(rand.coefs%*%c(1,last.yr+1))
var.site<-var(summary(trend.reml)$coeff$random$site[,1])/length(site.key)
se.pred<-sqrt(var.est+var.site)
aj.temps.bwh<-rnorm(nboot,mean=pred,sd=se.pred)
```

## 2.3.1 Streamflow Models
Initial model development was explored using the `streamflow_model_exlploration.R` script. The full suite of predictor variables were subset for each gage and the final set of predictor variables were determined using the `regsubsets` package, which enables visualization of adjusted R2 and BIC of each parameter set. 

```{r, Regsubsets BIC example, echo=FALSE, fig.aling="center", out.width = '80%', fig.pos='H'}
knitr::include_graphics("figures/BIC_regsubsets.png")
```

Final streamflow models are defined and synthesized in `streamflow_models.R`, this script also creates predictions for each model for the user defined year. Data is imported, and data structures are set up to save model output. The `modOut` function returns relevant metrics and statistics from the modeled results for the year being predicted. 

```{python, echo=TRUE, eval=FALSE, python.reticulate=FALSE}
modOut<- function(mod, pred.dat, wq, vol, meanSWE, lastQ){
  '
  mod:     input model
  pred.dat: data.frame of prediction variables
  wq:       array of historic winter flows (e.g. hist$cc.wq)
  vol:      array of historic april-sept volumes  (hist$cc.vol)
  meanSWE:  mean(arrays of historic SWE from ws snotel sites) #mean(hist$ccd+hist$sr, na.rm=T)
  lastQ:    last years summer streamflow volume (ac-ft) #var$cc.vol[var$year == pred.yr-1] 
  '
}
```

After this function is defined, the same set of steps occurs for each linear model. 
1) The model parameters are subset from the full data set, 
2) The linear model is created & summary metrics are saved, 
3) Prediction data is subset, 
4) Predictions are made, and outputs (estimated volume and standard error) are saved.


```{python, echo=TRUE, eval=FALSE, python.reticulate=FALSE}
# 1. Subset Big Wood Winter flows, snotel from  Galena & Galena Summit, Hyndman
hist <- var[var$year < pred.yr,] %>% select(bwb.vol.nat, g.swe, gs.swe, hc.swe) 
# 2. Create Big Wood at Hailey linear model
bwb_mod<-lm(log(bwb.vol.nat)~ g.swe+ log(gs.swe)+ hc.swe, data=hist) 
mod_sum[1,1]<-summary(bwb_mod)$adj.r.squared
# 3. Subset April 1 Prediction Data
pred.dat<-var[var$year == pred.yr,] %>% select(g.swe, gs.swe, hc.swe) 
# 4. Big Wood at Hailey Model output
mod_out<- modOut(bwb_mod, pred.dat, hist$bwb.wq, hist$bwb.vol.nat, mean(hist$g.swe,  
hist$gs.swe,  hist$hc.swe, trim=0, na.rm=T), var$bwb.vol.nat[var$year == pred.yr-1])
output.vol[1,] <- mod_out[[1]]
pred.params.vol[1,] <- mod_out[[2]] # standard error, "sigma"
```

After the streamflow volume model section of code, the same procedure is done for creating multivariate linear regressions for predicting center of mass, diversions, and curtailment dates. The curtailment date models are created after the volumes and diversions are predicted as those variables go into the curtailment date models. Here, model fits for irrigation season volume and center of mass ar shown together for each gage. 

```{python, echo=TRUE, eval=FALSE, python.reticulate=FALSE}
# Big Wood at Hailey Natural Flow Volume model
bwb_mod<-lm(log(bwb.vol.nat)~ g.swe+ log(gs.swe)+ hc.swe, data=hist) 
# BW Hailey Natural Flow Center of Mass model
bwb_mod.cm <-lm(bwb.cm.nat ~ log(bwb.wq) + g.swe+ hc.swe+ t.g +t.gs+t.lw+ 
log(cg.swe)+log(gs.swe), data=hist)
```

```{r, Big Wood Hailey Model Fits, echo=FALSE, fig.show="hold", out.width = '50%', fig.pos='H'}
knitr::include_graphics(c(file.path(params$fig_dir_mo, "BWB_modelFit.png"), file.path(params$fig_dir_mo, "BWB_CMmodelFit.png")))
```

### Big Wood at Stanton Crossing

```{python, echo=TRUE, eval=FALSE, python.reticulate=FALSE}
# Big Wood at Stanton Natural Flow Volume model
bws_mod<-lm(log(bws.vol.nat)~bws.wq+ log(g.swe) + log(gs.swe)+ log(hc.swe), data=hist) 
# Big Wood at Stanton Natural Flow Center of Mass model
bws_mod.cm <-lm(bws.cm.nat ~ lwd.swe +log(cg.swe)+log(hc.swe) + t.cg + t.g + t.hc + t.lw, data=hist)
```

```{r, Big Wood Stanton Model Fit, echo=FALSE, fig.cap="", fig.show="hold", fig.aling="left", out.width = '45%', fig.pos='H'}
knitr::include_graphics(c(file.path(params$fig_dir_mo, "BWS_modelFit.png"), file.path(params$fig_dir_mo, "BWS_CMmodelFit.png")))
```

### Silver Creek

The Silver Creek Model is unique in that it uses a mixture of SWE data from both the Big Wood and Little Wood Basins. While it is not traditional to use SWE from outside of a delineated HUC basin, none of the SNOTEL sites are adequate representations of the snow that is contributing to the Silver Creek Watershed. Given this data limitation and the groundwater interactions between Big Wood and Silver Creek, the model includes SWE data from Galena, Chocolate Gulch, and Swede Peak. This is one utility of using a statistical model, namely if SWE from these locations are correlated to flows in Silver Creek historically, they can do a sufficient job of predicting flows in the basin. Further discussion on viable next steps for the Silver Creek Model are discussed in the Recommendations section. 


```{python, echo=TRUE, eval=FALSE, python.reticulate=FALSE}
# Silver Creek Flow model, note mixture of SWE from Big Wood and Little Wood basins
sc_mod<-lm(log(sc.vol.nat)~ sc.wq+ga.swe + g.swe + log(hc.swe) + log(bwb.wq), data=hist)
# Silver Creek Natural Flow Center of Mass model

```

```{r, Silver Creek Model Fit, echo=FALSE, fig.cap="", fig.show="hold", fig.aling="left", out.width = '45%', fig.pos='H'}
knitr::include_graphics(c(file.path(params$fig_dir_mo, "SC_modelFit.png"), file.path(params$fig_dir_mo, "SC_CMmodelFit.png")))
```

### Camas Creek

```{python, echo=TRUE, eval=FALSE, python.reticulate=FALSE}
# Camas Creek Flow Volume model
cc_mod<-lm(log(cc.vol)~log(cc.wq)+sr.swe+ccd.swe, data=hist) 
# Camas Creek Center of Mass model
cc_mod.cm<-lm(cc.cm~ccd.swe + sr.swe+ t.f, data=hist) 
```

```{r, Camas Creek Model Fit, echo=FALSE, fig.cap="", fig.show="hold", fig.aling="left", out.width = '45%', fig.pos='H'}
knitr::include_graphics(c(file.path(params$fig_dir_mo, "CC_modelFit.png"), file.path(params$fig_dir_mo,"CC_CMmodelFit.png")))
```

### Big Wood Diversions
```{python, echo=TRUE, eval=FALSE, python.reticulate=FALSE}
# Total Big Wood Diversion Volume linear model 
div_mod<-lm(log(var$div[var$year >=1997 & var$year < pred.yr]) ~ log(cg.swe)+log(hc.swe)
+log(bws.wq), data=hist) 
# Data is subset to after 1997 when the Big Wood at Stanton gage came on board, 
# revisit this model using bwb.wq so we can use the full dataset
```

```{r, Big Wood Diversions Model Fit, echo=FALSE, fig.show="hold", fig.aling="center", out.width = '45%', fig.pos='H'}
knitr::include_graphics(file.path(params$fig_dir_mo, "Diversions_modelFit.png"))
```

### Silver Creek Diversions

```{python, echo=TRUE, eval=FALSE, python.reticulate=FALSE}
sc.div_mod<-lm(log(var$sc.div[var$year>1993 & var$year < pred.yr]) ~ g.swe+ temps+log(cg.swe)+log(lwd.swe), data=hist) 
```

```{r,Silver Creek Diversions Model Fit, echo=FALSE, fig.cap="", fig.show="hold", fig.aling="center", out.width = '45%', fig.pos='H'}
knitr::include_graphics(file.path(params$fig_dir_mo, "SC_Diversions_modelFit.png"))
```

## 2.3.2 Streamflow Correlations 

Given the proximity of the three basins, correlations between the basins' total annual irrigation season streamflow, diversions, and center of mass allow us to ensure that the predicted flows at each gage are representative of how regional climatic patterns will be effecting all locations. For example, we would not expect Camas Creek to have an exceptionally dry year in a year when the Big Wood is experiencing an exceptionally high streamflow year. The correlation between sites is combined with the standard error from each linear model to create a covariance matrix which is use to bootstrap model predictions.


```{python, echo=TRUE, eval=FALSE, python.reticulate=FALSE}
# Correlation matrix between streamflow volumes, diversions and centers of mass
cor.mat<-cor(cbind(flow.data[c(1,3,5,7,9,10)],flow.data[c(2,4,6,8)]),use="pairwise.complete")
# Create covariance matrix by multiplying by each models standard error
# pred.pars[1,]: fitted values; pred.pars[2,]: sigma (standard error)  
pred.pars<-rbind(pred.params.vol, pred.params.div, pred.params.cm) 
outer.prod<-as.matrix(pred.pars[,2])%*%t(as.matrix(pred.pars[,2])) 
cov.mat<-cor.mat*outer.prod
```

```{r, Covariance_matrix, echo=FALSE, fig.cap="Correlation matrix between gages", fig.aling="left", out.width = '100%', fig.pos='H'}
knitr::include_graphics(file.path(params$fig_dir_mo, "correlation_matrix.png"))
```

Flow volumes are then sampled from the multivariate distribution.

```{python, echo=TRUE, eval=FALSE, python.reticulate=FALSE}
vol.pars<-rbind(pred.params.vol, pred.params.div) # only use predictions from volume models
vol.sample<-mvrnorm(n=5000,mu=(vol.pars[,1]),Sigma=cov.mat[1:5,1:5]) # historical covariance of volumes
```

This results in a distribution of potential volumes for each gage, given the input predictor variables.
-- put in a figure here showing the distribution of results as an example of the output 

```{r, Sampled Volumes, echo=FALSE, fig.cap="Distrubution of sampled volumes at each gage", fig.aling="left", out.width = '100%', fig.pos='H'}
knitr::include_graphics(file.path(params$fig_dir_mo, "sampled_volumes.png"))
```

A similar process is used for estimating the timing of runoff.

```{python, echo=TRUE, eval=FALSE, python.reticulate=FALSE}
cm.data = var[var$year >= 1997 & var$year < pred.yr,] # only use complete dataset
cm.data = cm.data %>% select(year, bwb.cm.nat, bws.cm.nat,cc.cm, sc.cm) 
cm.data$prob<-NA

# pmvnorm calculates the distribution function of the multivariate normal distribution
for(i in 1:dim(cm.data)[1]){
  vec<-cm.data[i,2:5]
  cm.data$prob[i]<-pmvnorm(lower=as.numeric(vec)-0.5,
                          upper=as.numeric(vec)+0.5,mean=pred.params.cm[,1],sigma=cov.mat[6:9,6:9])[1]
}
cm.data$prob<-cm.data$prob/sum(cm.data$prob) # turn into percentage 
# create array of years based on their similarity to prediction year
CMyear.sample<-sample(cm.data$year,5000,replace=TRUE, prob=cm.data$prob)
```

```{r, CM summary, echo=FALSE, fig.cap="Summary of center of mass sample", fig.aling="center", out.width = '40%', fig.pos='H'}
knitr::include_graphics(file.path(params$fig_dir_mo, "CM_summary_prob.png"))
```

The resulting matrices are then saved as `.csv` to be used in the final simulation model.

## 2.4 Curtailment Date Models

Many of the individual curtailment models fit very well to historic data, as show in the Big Wood WR 10/14/1884 below.

```{r, bw curt mod, echo=FALSE, fig.cap="Summary of curtailment models and 2016 predictions", fig.aling="center", out.width = '90%', fig.pos='H'}
knitr::include_graphics(file.path(params$fig_dir_mo, "BigWoodB_curtailment.png"))
```

```{r, curt summary, echo=FALSE, fig.cap="Summary of curtailment models", fig.aling="center", out.width = '90%', fig.pos='H'}
knitr::include_graphics(file.path(params$fig_dir_mo, "curt_summary.png"))
```

The challenge with these models is once all of the predicted variables are included in the model for the upcoming year, the variability increases significantly.

```{r, curt summary w 2016 data, echo=FALSE, fig.cap="Summary of curtailment models and 2016 predictions", fig.aling="center", out.width = '90%', fig.pos='H'}
knitr::include_graphics(file.path(params$fig_dir_mo, "curt_summary_2016.png"))
```

```{r, curt 2019, echo=FALSE, fig.cap="Summary of curtailment models and 2019 predictions", fig.aling="center", out.width = '90%', fig.pos='H'}
knitr::include_graphics(file.path(params$fig_dir_mo, "curt_summary_2019.png"))
```

```{r, sampled curt, echo=FALSE, fig.cap="Sampled curtailment dates for 2020", fig.aling="center", out.width = '90%', fig.pos='H'}
knitr::include_graphics(file.path(params$fig_dir_mo, "sampled_curtailments.png"))
```
## 2.5 Streamflow Simulation

The final irrigation season streamflow simulations are modeled in the `streamflow_simulation.R` script.

The original streamflow data, sampled volumes and centers of mass are imported and the irrigation season hydrographs are simulated. This is done by selecting the timeseries of natural flow that corresponds with a given year from the center of mass sample and normalizing it by a volume from the multivariate distribution sample. This 'analog water year' approach effectively uses the linear models to estimate the most similar year in runoff timing, and normalizes (another way to say this?) that hydrograph based on the predicted volume estimates.

```{python, echo=TRUE, eval=FALSE, python.reticulate=FALSE}
for(k in 1:ns){ # ns = number of simulations, in our case 5000
  # Simulate natural flow supply at the four gages and total diversions
  year<-cm.year[k,1] # year sample
  vol<-volumes[k,] # volume sample
  
  # select the streamflow timeseries that corresponds with the center of mass sample
  bwb<- bwb.wy[bwb.wy$wy == year, "bwb.nat.q"][183:365]  # irrigation season 
  # normalize the sampled hydrograph by the sampled volume
  bwb.flow.s[,k]<- bwb * vol/(sum(bwb)*1.98) 
  # 1.98 is the conversion from cfs to ac-ft, (cfs) * (ac-ft/ac-ft)
```

Prediction intervals are calculated from the relevant quantiles from the simulation results
```{python, echo=TRUE, eval=FALSE, python.reticulate=FALSE}
pred.int<-function(location){
  lo<-apply(location,1,quantile,0.05, na.rm=TRUE)
  hi<-apply(location,1,quantile,0.95, na.rm=TRUE)
  meanQ<-apply(location,1,mean, na.rm=TRUE)
  
  return(cbind(lo, hi, meanQ))
}
```

The following figure is an example model output figure for each basin, the average simulated hydrograph (blue), the prediction interval (shaded grey), and the actual hydrograph (green) for 2019. 
```{r, testr, echo=TRUE}
knitr::include_graphics(file.path(params$fig_dir_mo, "BWB_Simulation.png"))
```

```{r, BWH Simulation, echo=FALSE, fig.cap="Simulated flows on the Big Wood River at Hailey", fig.aling="left", out.width = '100%', fig.pos='H'}
knitr::include_graphics("figures/BigWood_Hailey_Simulation_2019.png")
```

```{r, BWS Simulation, echo=FALSE, fig.cap="Simulated flows on the Big Wood River at Stanton Crossing", fig.aling="left", out.width = '100%', fig.pos='H'}
#knitr::include_graphics("figures/BigWood_Stanton_Simulation.png")
```

```{r, SC Simulation, echo=FALSE, fig.cap="Simulated flows on Silver Creek", fig.aling="left", out.width = '100%', fig.pos='H'}
#knitr::include_graphics("figures/Silver_creek_Simulation.png")
```

```{r, CC Simulation, echo=FALSE, fig.cap="Simulated flows on Camas Creek", fig.aling="left", out.width = '100%', fig.pos='H'}
#knitr::include_graphics("figures/Camas_creek_Simulation.png")
```

# 3. Overview of modeling results

While many of the individual linear regression models have strong fits, the compounding effects of multiple predictions make for large uncertainty windows. This is both valuable (ensures appropriate uncertainty in modeling results), and challenging for desired use of the model (narrower prediction windows for crop / irrigation planning). This initial suite of models (6 temperature, 16 streamflow, 9 curtailment) and the automated process lays a strong groundwork for future model development which will likely be necessary to create a modeling suite that can fulfill the needs of the WRWC. Continued model development should focus on the components of the hydrograph that are most valuable to the members, namely the hydrograph recession. Ideally those modeling results would be available by April, but the largest uncertainty in the current models are spring weather (e.g. once we've reached the peak of the hydrograph, predicting the recession is relatively straight forward, but by that time it is later than needed by users.) Maintaining focus on the desired use of the model will be critical in prioritizing the next steps. 

# 4. Recommendations

* continue to update diversion data annually
* Explore snow covered extent modeling
* Incorporate prediction data from the National Operational Hydrologic Remote Sensing Center, and other regional forecasting centers (summer temperatures in particular)
* Conduct a sensitivity analysis on prediction results to identify the most sensitive predictor variables, particularly on streamflow recession
* Evaluate alternative combinations and prediction windows for temperatures (e.g. June-July temperatures specifically for diversions)
* Evaluate alternative center of mass calculation methods (e.g. different timing windows such as April - July)
* Evaluate alternative methods for estimation of curtailment dates using all water right data
* Incorporate downstream water rights for Silver Creek and GW diversions
* Evaluate use of available groundwater data (there may not be enough for this to be viable)
* Evaluate alternative methods to enable running models on alternative dates


# 5. Citations

(2008) Bayesian Information Criteria. In: Information Criteria and Statistical Modeling. Springer Series in Statistics. Springer, New York, NY. https://doi.org/10.1007/978-0-387-71887-3_9

